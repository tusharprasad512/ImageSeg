# -*- coding: utf-8 -*-
"""CNN-R83.96.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I1VaE72rZq4KLAMOsow63KtUfLGh00Ky
"""

# Mount google drive to facilitate importing of data 
from google.colab import drive
drive.mount('/content/gdrive')

#unzip train images on the cloud
!unzip 'gdrive/My Drive/grid2019/trainImage.zip'

import os
import glob
import pandas as pd
import numpy as np
# to read images into a 3D numpy array
import cv2

# Keras functionalities
from keras.utils import to_categorical
import keras
from keras.models import Sequential
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D,AveragePooling2D 
from keras import regularizers
from keras.layers.normalization import BatchNormalization

train = pd.read_csv("gdrive/My Drive/grid2019/training.csv")
test = pd.read_csv("gdrive/My Drive/grid2019/test.csv")

def preprocessing(train,path,size):
  """
  Get X and y for your model after preprocessing your training images
  X = list of 3D Numpy arrays of training images
  y = list of bounding box co-ordinates
  
  -----------------------
  Parameters: 
  1. train (training.csv) dataframe
  2. path to the actual training images
  3. size = dimensions to which you want to resize your images of the 
  ------------------------
  Return:
  X and y as discussed above
  
  """
   
  train_names=train.iloc[:,0] 
  train_coordinates = train.drop(['image_name'],axis= 1) 
  train_images=[] 

  for i,name in enumerate(train_names):
      for image in glob.glob(os.path.join(path, name)):
          img = cv2.imread(image)
          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
          w,h = img.shape
          x1,x2,y1,y2 = train_coordinates.values[i]
          x1 = int(x1*size/h)
          y1 = int(y1*size/w)
          x2 = int(x2*size/h)
          y2 = int(y2*size/w)
          train_coordinates.values[i] = x1,x2,y1,y2
          img = cv2.resize(img, (size,size))
          train_images.append(img) 

  print("done")
  
  return train_images, train_coordinates


size=96
path = '/content/images_train/' 
X,y=preprocessing(train,path,size)
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
X=np.reshape(X,(14000,96,96,1))

np.shape(X)



def CNN_Regression():
    """
    Description: Architecture of the CNN-R model 
    """
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(size, size, 1)))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
  
    model.add(Flatten())
    model.add(Dense(1024,  activation='relu',kernel_regularizer=regularizers.l2(0.01)))
    model.add(Dropout(0.5))
    model.add(Dense(512,  activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4))
#   model.add(Activation('linear'))
    
    model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False))
    
    return model

def train_model(type):
  
  if type==1:
    X_train= np.array(X[0:12000])
    y_train=y[0:12000].values
    X_test=np.array(X[12000:14000])
    y_test=y[12000:14000].values  

    # checkpoint_path = "gdrive/My Drive/grid2019/modelcnn.hdf5"
    # checkpoint_dir = os.path.dirname(checkpoint_path)

    # callbacks = [
    # # EarlyStopping(monitor='loss', min_delta=0.0001, patience=2,verbose=1, mode='auto'),
    # ModelCheckpoint(filepath=checkpoint_path,monitor='loss', verbose=0, save_best_only=True),
    # ]
    model=CNN_Regression()
    model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(X_test, y_test))
  
  else:
    X_train= np.array(X[0:14000])
    y_train=y[0:14000].values
#     X_test=np.array(X[12000:14000])
#     y_test=y[12000:14000].values  

    # checkpoint_path = "gdrive/My Drive/grid2019/modelcnn.hdf5"
    # checkpoint_dir = os.path.dirname(checkpoint_path)

    # callbacks = [
    # # EarlyStopping(monitor='loss', min_delta=0.0001, patience=2,verbose=1, mode='auto'),
#     ModelCheckpoint(filepath=checkpoint_path,monitor='loss', verbose=0, save_best_only=True),
    model=CNN_Regression()
    model.fit(X_train, y_train, batch_size=32, epochs=200, verbose=1)
    
  return model 


"""
Enter 1 to train on 12000 Training and 2000 Validation Images
Enter 2 to train entirely on 14000 Training Images

"""    

model= train_model(2)

"""

Saving Models to drive

"""
model_json = model.to_json()
with open("gdrive/My Drive/models/model_bettergray.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("gdrive/My Drive/models/model_weights_bettergray.h5")
print("Saved model to drive")

"""

"""
X_test=np.array(X[12000:14000])
y_test=y[12000:14000].values  
y_pred = model.predict(X_test)

w=480
h=640
print(size)
for i in range(2000):
  x1_pred,x2_pred,y1_pred,y2_pred = y_pred[i]
  x1_pred = int(x1_pred*h/size+2)
  y1_pred = int(y1_pred*w/size+2)
  x2_pred = int(x2_pred*h/size+2)
  y2_pred = int(y2_pred*w/size+2)
  y_pred[i] = x1_pred,x2_pred,y1_pred,y2_pred
  
for i in range(2000):
  x1_test,x2_test,y1_test,y2_test = y_test[i]
  x1_test = int(x1_test*h/size+2)
  y1_test = int(y1_test*w/size+2)
  x2_test = int(x2_test*h/size+2)
  y2_test = int(y2_test*w/size+2)
  y_test[i] = x1_test,x2_test,y1_test,y2_test

def get_iou(bb1, bb2):
    """
    Calculate the Intersection over Union (IoU) of two bounding boxes.

    Parameters
    ----------
    bb1 : ndarray [x1,x2,y1,y2]
        The (x1, y1) position is at the top left corner,
        the (x2, y2) position is at the bottom right corner
    bb2 : ndarray [x1,x2,y1,y2]
        The (x, y) position is at the top left corner,
        the (x2, y2) position is at the bottom right corner
        
        0:x1, 1:x2, 2:y1, 3:y2

    Returns
    -------
    float in [0, 1]
        
    """
    assert bb1[0] < bb1[1]
    assert bb1[2] < bb1[3]
    assert bb2[0] < bb2[1]
    assert bb2[2] < bb2[3]

    # determine the coordinates of the intersection rectangle
    x_left = max(bb1[0], bb2[0])
    y_top = max(bb1[2], bb2[2])
    x_right = min(bb1[1], bb2[1])
    y_bottom = min(bb1[3], bb2[3])

    if x_right < x_left or y_bottom < y_top:
        return 0.0

    # The intersection of two axis-aligned bounding boxes is always an
    # axis-aligned bounding box
    intersection_area = (x_right - x_left) * (y_bottom - y_top)

    # compute the area of both AABBs
    bb1_area = (bb1[1] - bb1[0]) * (bb1[3] - bb1[2])
    bb2_area = (bb2[1] - bb2[0]) * (bb2[3] - bb2[2])

    # compute the intersection over union by taking the intersection
    # area and dividing it by the sum of prediction + ground-truth
    # areas - the interesection area
    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)
    assert iou >= 0.0
    assert iou <= 1.0
    return iou

iou=0
for i in range(2000):
  if i%100==0:
    print(y_test[i])
    print(y_pred[i])
  iou=iou+get_iou(y_test[i],y_pred[i])
iou=iou/2000
print(iou)

from keras.models import model_from_json

# load json and create model
json_file = open('gdrive/My Drive/models/model_better826.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("gdrive/My Drive/models/model_weights_better826.h5")
print("Loaded model from disk")

!unzip 'gdrive/My Drive/grid2019/testImage.zip'



def preprocessing_test(test,path,size):
  """
  Get X and y for your model after preprocessing your training images
  
  """

  '''
    You will get the preprocessed list of every training image after running this cell(14000 x 224 x 224 x 3) 
    and the scaled co-ordinates of their corresponding bounding boxes
    

  '''
  
  test_names=test.iloc[:,0] #To get the names of every train image, indexed as per training.csv

  
  test_images=[] # will contain the 3D numpy version of all the training images 14000 x 224 x 224 x 3

  for i,name in enumerate(test_names):
#       print(i)
      for image in glob.glob(os.path.join(path, name)):
          img = cv2.imread(image)
          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

          img = cv2.resize(img, (size,size))
          test_images.append(img) 

  print("done")
  
  return test_images


size=96
path_test = '/content/images_test/' #path to actual training images
X_test_final=preprocessing_test(test,path_test,size)

X_test_final=np.reshape(X_test_final,(12815,96,96,1))
np.shape(X_test_final)

y_pred_final = model.predict(np.array(X_test_final))
y_pred_final[0]

y_pred_final.shape[0]

w=480
h=640
for i in range(y_pred_final.shape[0]):
  x1_pred,x2_pred,y1_pred,y2_pred = y_pred_final[i]
  x1_pred = int(x1_pred*h/size+2)
  y1_pred = int(y1_pred*w/size+2)
  x2_pred = int(x2_pred*h/size+2)
  y2_pred = int(y2_pred*w/size+2)
  y_pred_final[i] = x1_pred,x2_pred,y1_pred,y2_pred

y_pred_final[0]

y_pred_final.shape

y_pred_df = pd.DataFrame({'x1':y_pred_final[:,0],'x2':y_pred_final[:,1],'y1':y_pred_final[:,2],'y2':y_pred_final[:,3]})

test_names=test.iloc[:,0]
y_pred_df.insert(loc=0, column='image_name', value=test_names)
y_pred_df.head()



test.head()

y_pred_df.to_csv('test_predgray.csv', index=False)

!cp test_predgray.csv gdrive/My\ Drive/

prediction_file=pd.read_csv("/content/gdrive/My Drive/test_pred2.csv")

prediction_file.head()

prediction_file.shape

test.shape

model.summary()

